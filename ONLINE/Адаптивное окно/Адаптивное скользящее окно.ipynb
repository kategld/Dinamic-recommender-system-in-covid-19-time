{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "алгоритм https://epubs.siam.org/doi/pdf/10.1137/1.9781611972771.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import surprise\n",
    "import dateutil.relativedelta\n",
    "from datetime import timezone\n",
    "from cornac.metrics import MAE, RMSE, Precision, Recall, NDCG, AUC, MAP\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from surprise import SVD, NMF\n",
    "from surprise import Reader, Dataset\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подготовка данных\n",
    "bounds = {'before_covid':[datetime.datetime(2020,1,1), datetime.datetime(2020,3,20)],\n",
    "          'during_covid':[datetime.datetime(2020,3,20), datetime.datetime(2020,8,1)], \n",
    "          'after_covid':[datetime.datetime(2020,8,1), datetime.datetime(2020,10,1)]}\n",
    "def func(date):\n",
    "    if date<=bounds['before_covid'][1]:\n",
    "        return 0\n",
    "    if bounds['during_covid'][0]<=date<=bounds['during_covid'][1]:\n",
    "        return 1\n",
    "    if bounds['after_covid'][0]<=date:\n",
    "        return 2\n",
    "def add_new_columns_with_context(df):\n",
    "    df = df.sort_values('date', ascending=False)\n",
    "    df.drop_duplicates(subset=['user_name', 'unique_rest'], inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col,inplace=True,axis=1)\n",
    "    df.drop_duplicates(subset=['user_name', 'unique_rest'], inplace=True)\n",
    "#оставляем пользователей с количеством отзывов >1\n",
    "    users = df.groupby('user_name')['rating'].count()[df.groupby('user_name')['rating'].count()>1].index.tolist()\n",
    "    df = df[df.user_name.isin(users)]\n",
    "    q_dict = df.drop_duplicates('unique_rest').groupby('city')['dist'].describe()[['25%', '50%', '75%']]\n",
    "    q_df = q_dict.to_dict('index')\n",
    "    #название городов в числа\n",
    "    city2cat_dict = {x:i for i,x in enumerate(df['city'].unique().tolist())}\n",
    "    print(city2cat_dict)\n",
    "    df['city'] = df['city'].apply(lambda x: city2cat_dict[x])\n",
    "    # текущее количество отзывов у пользователя\n",
    "    df['covid'] = df.date.apply(lambda x: func(x))\n",
    "    return df\n",
    "def for_city(df):\n",
    "    #контекст отзыва\n",
    "    #перцентиль по контексту\n",
    "    df.drop(['text', 'rest_name', 'neg', 'neu', 'pos', 'review_language', 'average_rating',\n",
    "         'num_all_rev',\"country\"], axis=1, inplace=True)\n",
    "    norm = ['user_name','unique_rest','date']\n",
    "    for col in df.columns:\n",
    "        if col not in norm:\n",
    "            df[col] = df[col].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df,date_start,date_end):\n",
    "    df_train = df[(df.date.between(date_start-dateutil.relativedelta.relativedelta(months=6), \n",
    "                                   date_start-dateutil.relativedelta.relativedelta(days=1)))]\n",
    "    df_test = df[(df.date.between(date_start, date_end))]\n",
    "    #пользователи и рестораны только те которые в трейне\n",
    "    df_test = df_test[(df_test.user_name.isin(df_train.user_name.unique().tolist()))\n",
    "                       &(df_test.unique_rest.isin(df_train.unique_rest.unique().tolist()))]\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_calculate(n1,n2): \n",
    "    return 1/(1/n1+1/n2) \n",
    "def delta_calculate(delta,n):\n",
    "    return delta/n\n",
    "def epsilon_calculate(m,delta): \n",
    "    return math.sqrt((1/(2*m))*math.log(4/delta))\n",
    "def checking_stop_condition(train,date_group,border,delta):\n",
    "    condition_value=1\n",
    "    for i in range(1,int(border/5)-1):\n",
    "        train1=train[train.date_new<date_group-i*5]\n",
    "        train2=pd.concat([train,train1]).drop_duplicates(keep=False)\n",
    "        n1=len(train1)\n",
    "        n2=len(train2)\n",
    "        mu1=train1.rate.mean()\n",
    "        mu2=train2.rate.mean()\n",
    "        try:\n",
    "            eps=epsilon_calculate(m_calculate(n1,n2),delta_calculate(delta,n1+n2))\n",
    "            if(abs(mu1-mu2)>=eps):\n",
    "                condition_value=condition_value*0\n",
    "        except:\n",
    "            eps=0\n",
    "    return condition_value\n",
    "def find_train_set(train_all,date_group,border,delta):\n",
    "    train=train_all[train_all.date<date_group]\n",
    "    train_new=pd.DataFrame()\n",
    "    window_size=0\n",
    "    for i in range(1,int((31*border/3))):\n",
    "        train_new=train[train.date>date_group-np.timedelta64(31*border, 'D')+np.timedelta64(3*i, 'D')]\n",
    "        window_size=len(train_new.date.unique())\n",
    "        if(checking_stop_condition(train_new,date_group,border,delta)):\n",
    "            break\n",
    "    return train_new,window_size   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addaptive_window_alg(df,bounds,city,border,delta):\n",
    "    results_surprise = pd.DataFrame()\n",
    "    ndcg = NDCG(10)\n",
    "    all_pred = pd.DataFrame()\n",
    "    for i,k in enumerate(bounds.keys()):\n",
    "        print(bounds[k][0], bounds[k][1])\n",
    "        df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "        df_train=df_train[['user_name', 'unique_rest', 'rating',\"date\"]]\n",
    "        df_test=df_test[['user_name', 'unique_rest', 'rating','date']]\n",
    "        test_covid=df_test\n",
    "        train_all=df\n",
    "        groups=test_covid.date.unique()\n",
    "        ndcg_metric = {}\n",
    "        met = pd.DataFrame()\n",
    "        for date_group in groups:\n",
    "            test=test_covid[test_covid.date==date_group]\n",
    "            train,window_size=find_train_set(train_all,date_group,border,delta)\n",
    "            #print(date_group,window_size)\n",
    "    #print(len(train))\n",
    "            df_train=train[['user_name', 'unique_rest', 'rating']]\n",
    "            df_test=test[['user_name', 'unique_rest', 'rating']]\n",
    "            reader = Reader(rating_scale=(1, 5))\n",
    "            data_do_train = Dataset.load_from_df(df_train, reader)\n",
    "            trainset = data_do_train.build_full_trainset()\n",
    "            algo = SVD()\n",
    "            algo.fit(trainset)\n",
    "            df_test_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "            df_test_ = df_test_[df_test_.index.isin(df_test.user_name.unique().tolist())]\n",
    "            df_test_.update(df_test.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0))\n",
    "            df_train_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "            df_train_ = df_train_[df_train_.index.isin(df_train.user_name.unique().tolist())]\n",
    "            df_test_dict = df_test_.T.to_dict('list')\n",
    "    #df_test_dict_all\n",
    "            us = {}\n",
    "    #print(df_test_.index.tolist())\n",
    "            for u in df_test_.index.tolist():\n",
    "                values = [algo.predict(u, i).est if df_train_.loc[u, i]==0 else 0 for i in df_test_.columns.tolist()]\n",
    "                us[u] = values\n",
    "            for kk in us.keys():\n",
    "                val=ndcg.compute(df_test_dict[kk], np.array(us[kk]).argsort()[::-1])\n",
    "                if (not math.isnan(val)):\n",
    "                    ndcg_metric[kk] = val\n",
    "        ndcg_ = np.mean(list(ndcg_metric.values()))\n",
    "        met = met.append({\n",
    "            'alg':\"SVD c аддаптивным окном\",\n",
    "            'period': (str(bounds[k][0])[:7]+' - '+str(bounds[k][1])[:7]),\n",
    "            \"city\":city,\n",
    "        #'rmse': rmse,\n",
    "        #'mae': mae,\n",
    "            'ndcg10': ndcg_,\n",
    "            }, ignore_index=True)\n",
    "        all_pred = all_pred.append(met, ignore_index=True)\n",
    "    return all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\Anaconda3\\Scripts\\Диплом\\ONLINE EXCPERIMENT\\GIT/FINAL_REVWS_ALL.csv', index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rome': 0, 'NY': 1, 'Stockholm': 2, 'Los': 3, 'saint': 4}\n"
     ]
    }
   ],
   "source": [
    "df_all=df.copy()\n",
    "cities=['Los', 'NY','Rome','Stockholm','saint']\n",
    "df_all=df_all[df_all.city.isin(cities)]\n",
    "df_all=add_new_columns_with_context(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-01 00:00:00 2020-10-01 00:00:00\n",
      "1\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-01 00:00:00 2020-10-01 00:00:00\n",
      "2\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-01 00:00:00 2020-10-01 00:00:00\n",
      "3\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-01 00:00:00 2020-10-01 00:00:00\n",
      "4\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-01 00:00:00 2020-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "all_city_pred=pd.DataFrame()\n",
    "border=2\n",
    "delta=0.5\n",
    "for city in range(0,len(cities)):\n",
    "    print(city)\n",
    "    df=df_all[df_all.city==city]\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=for_city(df)\n",
    "    window_method=addaptive_window_alg(df,bounds,city,border,delta)\n",
    "    all_city_pred=pd.concat([all_city_pred,window_method], ignore_index=True)\n",
    "    all_city_pred.to_csv(\"C:\\Anaconda3\\Scripts\\Диплом\\ONLINE EXCPERIMENT\\GIT\\Адаптивное окно/\"\n",
    "                         +\"all_city_adaptive\"+str(border)+\".csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стандартные рекомендательгные алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.SVD()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg\n",
    "def svd_model(user_code,alg,upper_border,all_data,crd):\n",
    "    pred=[]\n",
    "    for place in all_data.place_code.unique():\n",
    "        pred.append(alg.predict(uid=user_code,iid=place).est)   \n",
    "    svd_rating=dict(zip(all_data.place_code.unique(),pred)) \n",
    "    svd_rating={k: v for k, v in sorted(svd_rating.items(), key=lambda item: item[1],reverse=True)}\n",
    "    return svd_rating\n",
    "def svd_crd_model(user_code,alg,upper_border,all_data,crd):\n",
    "    pred=[]\n",
    "    for place in all_data.place_code.unique():\n",
    "        pred.append(alg.predict(uid=user_code,iid=place).est+crd)   \n",
    "    svd_rating=dict(zip(all_data.place_code.unique(),pred)) \n",
    "    svd_rating={k: v for k, v in sorted(svd_rating.items(), key=lambda item: item[1],reverse=True)}\n",
    "    return svd_rating\n",
    "def coll_filt(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    sim_options = {'name': 'cosine',\n",
    "               'user_based':True  # compute  similarities between items\n",
    "               }\n",
    "    alg=surprise.KNNWithMeans(sim_options=sim_options)\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg\n",
    "def baseline_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.prediction_algorithms.baseline_only.BaselineOnly()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg\n",
    "def normpred_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.prediction_algorithms.random_pred.NormalPredictor()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg    \n",
    "def nmf_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.NMF()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg    \n",
    "def slope_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.prediction_algorithms.slope_one.SlopeOne()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg\n",
    "def coclust_learning(train_set):\n",
    "    reader=surprise.Reader(rating_scale=(train_set.rate.min(),train_set.rate.max()))\n",
    "    data=surprise.Dataset.load_from_df(train_set,reader)\n",
    "    alg=surprise.prediction_algorithms.co_clustering.CoClustering()\n",
    "    output=alg.fit(data.build_full_trainset())\n",
    "    return alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_real_pred(real_glob,pred_glob,crd,test,alg_svd,coll,bl_alg,np_alg,slope_alg,coclust_alg,nmf_alg):\n",
    "    real_glob[0],pred_glob[0]=rmse_for_alg(test,alg_svd,svd_model,crd,real_glob[0],pred_glob[0])\n",
    "    real_glob[1],pred_glob[1]=rmse_for_alg(test,coll,svd_model,crd,real_glob[1],pred_glob[1])\n",
    "    real_glob[2],pred_glob[2]=rmse_for_alg(test,bl_alg,svd_model,crd,real_glob[2],pred_glob[2])\n",
    "    real_glob[3],pred_glob[3]=rmse_for_alg(test,np_alg,svd_model,crd,real_glob[3],pred_glob[3])\n",
    "    real_glob[4],pred_glob[4]=rmse_for_alg(test,nmf_alg,svd_model,crd,real_glob[4],pred_glob[4])\n",
    "    real_glob[5],pred_glob[5]=rmse_for_alg(test,slope_alg,svd_model,crd,real_glob[5],pred_glob[5])\n",
    "    real_glob[6],pred_glob[6]=rmse_for_alg(test,coclust_alg,svd_model,crd,real_glob[6],pred_glob[6])\n",
    "    real_glob[7],pred_glob[7]=rmse_for_alg(test,alg_svd,svd_crd_model,crd,real_glob[7],pred_glob[7])\n",
    "    return real_glob,pred_glob\n",
    "def rmse_for_alg(test,alg,svd_model,crd,real,pred):\n",
    "    r_p_one=rmse_for(test,alg,svd_model,crd)\n",
    "    real.extend(r_p_one[0])\n",
    "    pred.extend(r_p_one[1])\n",
    "    return real,pred\n",
    "def rmse_for(test_set,alg,svd_model,crd):\n",
    "    pred,real=[],[]\n",
    "    for user in test_set.user_code.unique():\n",
    "        rec_for_user=svd_model(user,alg,len(data.place_code.unique()),data,crd)\n",
    "        real,pred=real_pred(test_set,user,rec_for_user,pred,real)\n",
    "    return real,pred\n",
    "def real_pred(test_set,user,rec_for_user,pred,real):\n",
    "    test_per_user=test_set[test_set.user_code==user]\n",
    "    places=test_per_user.place_code\n",
    "    rates=test_per_user.rate\n",
    "    d=dict(zip(places,rates))\n",
    "    for i in d:\n",
    "        pred.append(rec_for_user[i])\n",
    "        real.append(d[i]) \n",
    "    return real,pred\n",
    "def rmse(real,pred):\n",
    "    for_i=0\n",
    "    for i in range(len(real)):\n",
    "        for_i+=(real[i]-pred[i])**2\n",
    "    return math.sqrt(for_i/len(real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Адаптивное скользящее окно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_calculate(n1,n2): \n",
    "    return 1/(1/n1+1/n2) \n",
    "def delta_calculate(delta,n):\n",
    "    return delta/n\n",
    "def epsilon_calculate(m,delta): \n",
    "    return math.sqrt((1/(2*m))*math.log(4/delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_stop_condition(train,date_group,border,delta):\n",
    "    condition_value=1\n",
    "    for i in range(1,int(border/5)-1):\n",
    "        train1=train[train.date_new<date_group-i*5]\n",
    "        train2=pd.concat([train,train1]).drop_duplicates(keep=False)\n",
    "        n1=len(train1)\n",
    "        n2=len(train2)\n",
    "        mu1=train1.rate.mean()\n",
    "        mu2=train2.rate.mean()\n",
    "        try:\n",
    "            eps=epsilon_calculate(m_calculate(n1,n2),delta_calculate(delta,n1+n2))\n",
    "            if(abs(mu1-mu2)>=eps):\n",
    "                condition_value=condition_value*0\n",
    "        except:\n",
    "            eps=0\n",
    "    return condition_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_train_set(train_all,date_group,border,delta):\n",
    "    train=train_all[train_all.date_new<date_group]\n",
    "    for i in range(1,int((border/3))):\n",
    "        train_new=train[train.date_new>date_group-border+3*i]\n",
    "        window_size=len(train_new.date_new.unique())\n",
    "        if(checking_stop_condition(train_new,date_group,border,delta)):\n",
    "            break\n",
    "    return train_new,window_size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addaptive_window(train_all,test_covid,border,delta):\n",
    "    rmse_global=[]\n",
    "    real_glob=[[],[],[],[],[],[],[],[]]\n",
    "    pred_glob=[[],[],[],[],[],[],[],[]]\n",
    "    groups=test_covid.date_new.unique()\n",
    "    for date_group in groups:\n",
    "        test=test_covid[test_covid.date_new==date_group]\n",
    "        train,window_size=find_train_set(train_all,date_group,border,delta)\n",
    "        print(date_group,window_size)\n",
    "        covid_mean=test.rate.mean()\n",
    "        without_covid=train[train.date_new<(1585318575-min_date)/(60*60*24)]\n",
    "        usual_mean=without_covid.rate.mean()\n",
    "        crd=covid_mean-usual_mean\n",
    "        if(np.isnan(crd)):\n",
    "            crd=0\n",
    "        alg_svd=svd_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        coll=coll_filt(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        bl_alg=baseline_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        np_alg=normpred_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        nmf_alg=nmf_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        slope_alg=slope_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        coclust_alg=coclust_learning(train[[\"user_code\",\"place_code\",\"rate\"]])\n",
    "        real_glob,pred_glob=create_global_real_pred(real_glob,pred_glob,crd,test,alg_svd,\n",
    "                                                    coll,bl_alg,np_alg,slope_alg,coclust_alg,nmf_alg)\n",
    "    for i in range(len(real_glob)):\n",
    "        rmse_global.append(rmse(real_glob[i],pred_glob[i]))\n",
    "    df=pd.DataFrame({\n",
    "        \"method\":[\"svd\",\"coll\",\"bl_alg\",\"np_alg\",\"nmf_alg\",\"slope\",\"coclust\",\"scd+crd\"],\n",
    "        \"rmse\":rmse_global \n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data,period):\n",
    "    min_date=data.date.min()\n",
    "    data[\"date_new\"]=[(date-min_date)/(60*60*24) for date in data.date]\n",
    "    train_all=data\n",
    "    #во время\n",
    "    if (period==\"in_time\"):\n",
    "        test_covid=data[data[\"date\"]>=1585318575]\n",
    "        test_covid=test_covid[test_covid[\"date\"]<=1598537775]\n",
    "    #после\n",
    "    if(period==\"after\"):\n",
    "        test_covid=data[data[\"date\"]<=1601501263]#1 октября\n",
    "        test_covid=test_covid[test_covid[\"date\"]>=1596230863]#1 августа\n",
    "    #до\n",
    "    if(period==\"before\"):\n",
    "        test_covid=data[data[\"date\"]>=1577827663]\n",
    "        test_covid=test_covid[test_covid[\"date\"]<=1584653263]\n",
    "    return train_all,test_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(path,data,period,border,delta):\n",
    "    train_all,test_covid=train_test(data,period)\n",
    "    df=addaptive_window(train_all,test_covid,border,delta)\n",
    "    df.to_csv(path+\"/\"+path+\"_\"+period+\"_адаптивный оконный метод.csv\",sep=\";\")\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для данных по разным странам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для данных по странам\n",
    "pathes=[\"paris\",\"istanbul\",\"berlin\",\"sankt-petersburg\",\"london\"]\n",
    "filenames=[]\n",
    "for i in pathes:\n",
    "    filenames.append(os.listdir(i))\n",
    "name=\"_data\"\n",
    "name_in_city=[]\n",
    "for i in filenames:\n",
    "    for j in i:\n",
    "        if (name in j):\n",
    "            name_in_city.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border=31*2\n",
    "delta=0.5\n",
    "#во время ковид\n",
    "for i in range(len(name_in_city)):\n",
    "    path=pathes[i]\n",
    "    data=pd.read_csv(path+\"/\"+path+\"_data.csv\",sep=\";\",index_col=\"Unnamed: 0\")\n",
    "    to_df(path,data,\"in_time\",border,delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
