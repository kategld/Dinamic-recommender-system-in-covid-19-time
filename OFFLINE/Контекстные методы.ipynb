{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from surprise import SVD, SVDpp, NMF, CoClustering, SlopeOne, NormalPredictor\n",
    "from surprise import Reader, Dataset\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "import dateutil.relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cornac.models import SKMeans, MostPop\n",
    "from cornac.metrics import MAE, RMSE, Precision, Recall, NDCG, AUC, MAP\n",
    "import cornac\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cities=['Los', 'NY','Rome','Stockholm','saint']\n",
    "c_num=4\n",
    "df = pd.read_csv('C:\\Anaconda3\\Scripts\\Диплом\\ONLINE EXCPERIMENT\\GIT/FINAL_REVWS_ALL.csv', index_col=0)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_columns_with_context(df):\n",
    "    df = df.sort_values('date', ascending=False)\n",
    "    df.drop_duplicates(subset=['user_name', 'unique_rest'], inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col,inplace=True,axis=1)\n",
    "    df.drop_duplicates(subset=['user_name', 'unique_rest'], inplace=True)\n",
    "#оставляем пользователей с количеством отзывов >1\n",
    "    users = df.groupby('user_name')['rating'].count()[df.groupby('user_name')['rating'].count()>1].index.tolist()\n",
    "    df = df[df.user_name.isin(users)]\n",
    "    q_dict = df.drop_duplicates('unique_rest').groupby('city')['dist'].describe()[['25%', '50%', '75%']]\n",
    "    q_df = q_dict.to_dict('index')\n",
    "    #по перцентилям \n",
    "    df['dist'] = dist2category(df.city, df.dist, q_df)\n",
    "    #название городов в числа\n",
    "    city2cat_dict = {x:i for i,x in enumerate(df['city'].unique().tolist())}\n",
    "    print(city2cat_dict)\n",
    "    df['city'] = df['city'].apply(lambda x: city2cat_dict[x])\n",
    "    # текущее количество отзывов у пользователя\n",
    "    df['cur_count'] = df.sort_values('date').groupby('user_name').cumcount()\n",
    "    df['cur_count'] = df.cur_count.apply(lambda x: int(cur_count2cur_count_category(x)))\n",
    "    df['covid'] = df.date.apply(lambda x: func(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_city(df):\n",
    "    #контекст отзыва\n",
    "    csum_pos = df.sort_values('date').groupby('user_name')['pos'].cumsum()\n",
    "    ccount_pos = df.sort_values('date').groupby('user_name')['pos'].cumcount()\n",
    "    cmean_pos = (csum_pos/ccount_pos).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    csum_neu = df.sort_values('date').groupby('user_name')['neu'].cumsum()\n",
    "    ccount_neu = df.sort_values('date').groupby('user_name')['neu'].cumcount()\n",
    "    cmean_neu = (csum_neu/ccount_neu).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    csum_neg = df.sort_values('date').groupby('user_name')['neg'].cumsum()\n",
    "    ccount_neg = df.sort_values('date').groupby('user_name')['neg'].cumcount()\n",
    "    cmean_neg = (csum_neg/ccount_neg).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['cur_cmean_pos'] = cmean_pos\n",
    "    df['cur_cmean_neu'] = cmean_neu\n",
    "    df['cur_cmean_neg'] = cmean_neg\n",
    "    #перцентиль по контексту\n",
    "    avgs = ['cur_cmean_pos','cur_cmean_neu', 'cur_cmean_neg']\n",
    "    tdict = df[(df[avgs]!=0).all(axis=1)][avgs].describe().T[['25%', '50%', '75%']].to_dict('index')    \n",
    "    for col in avgs:\n",
    "        print(col)\n",
    "        temp = [cur_sent2cur_sent_category(x, col, tdict) for x in df[col].tolist()]\n",
    "        df[col] = temp\n",
    "    df.drop(['text', 'rest_name', 'neg', 'neu', 'pos', 'review_language', 'average_rating',\n",
    "         'num_all_rev',\"country\"], axis=1, inplace=True)\n",
    "    norm = ['user_name','unique_rest','date']\n",
    "    for col in df.columns:\n",
    "        if col not in norm:\n",
    "            df[col] = df[col].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_count(df,bounds):\n",
    "    fi = dict()\n",
    "    rmse_CB = []\n",
    "    for i,k in enumerate(bounds.keys()):\n",
    "        print(bounds[k][0], bounds[k][1])\n",
    "        df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "        temp = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].mean().reset_index().rename(columns={'rating':'average_rating'})\n",
    "        temp['average_rating'] = temp.average_rating.apply(lambda x: ratata(x))\n",
    "        temp_avg_rating2cat_dict = {x:i for i,x in enumerate(temp['average_rating'].unique().tolist())}\n",
    "        temp['average_rating'] = temp['average_rating'].apply(lambda x: temp_avg_rating2cat_dict[x])\n",
    "        temp1 = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].count().reset_index().rename(columns={'rating':'num_all_rev'})\n",
    "        temp1['num_all_rev'] = temp1.num_all_rev.apply(lambda x: func_desc(x, temp1['num_all_rev'].describe()))\n",
    "        temp1_avg_rating2cat_dict = {x:i for i,x in enumerate(temp1['num_all_rev'].unique().tolist())}\n",
    "        temp1['num_all_rev'] = temp1['num_all_rev'].apply(lambda x: temp1_avg_rating2cat_dict[x])\n",
    "        df_train = df_train.merge(temp, on='unique_rest')\n",
    "        df_test = df_test.merge(temp, on='unique_rest')\n",
    "        df_train = df_train.merge(temp1, on='unique_rest')\n",
    "        df_test = df_test.merge(temp1, on='unique_rest')\n",
    "        X_train = df_train.drop(['rating',\n",
    "#                              'user_name',\n",
    "#                              'unique_rest',\n",
    "                             'date'\n",
    "                            ], axis=1)\n",
    "        y_train = df_train['rating']\n",
    "        X_test = df_test.drop(['rating',\n",
    "#                            'user_name',\n",
    "#                            'unique_rest',\n",
    "                           'date'\n",
    "                            ], axis=1)\n",
    "        y_test = df_test['rating']\n",
    "        cf = list(range(len(X_train.columns.tolist())))\n",
    "        CB = CatBoostRegressor(iterations=100)\n",
    "        CB.fit(X_train, y_train, cat_features=cf, verbose=False)\n",
    "        fi[i] = dict(zip(CB.feature_names_, CB.feature_importances_))\n",
    "        y_pred = CB.predict(X_test)\n",
    "        rmse = mean_squared_error(y_pred=y_pred, y_true=df_test.rating, squared=False)\n",
    "        rmse_CB.append(rmse)\n",
    "    fi = pd.DataFrame(fi)\n",
    "    fi_index = fi.sort_values(0, ascending=False)[0].head(20).index.tolist() + fi.sort_values(1, ascending=False)[1].head(20).index.tolist() + fi.sort_values(2, ascending=False)[2].head(20).index.tolist()\n",
    "    fi_index = list(set(fi_index))\n",
    "    fi[fi.index.isin(fi_index)].sort_values(1, ascending=False).to_csv(cntry+'fi_v1.csv')\n",
    "    fi[fi.index.isin(fi_index)].sort_values(1, ascending=False)\n",
    "    return fi,fi_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cntry = 'Russia'\n",
    "#df = df[df.country==cntry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rome': 0, 'NY': 1, 'Stockholm': 2, 'Los': 3, 'saint': 4}\n"
     ]
    }
   ],
   "source": [
    "cities=['Los', 'NY','Rome','Stockholm','saint']\n",
    "df_all=df_all[df_all.city.isin(cities)]\n",
    "df_all=add_new_columns_with_context(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cur_cmean_pos\n",
      "cur_cmean_neu\n",
      "cur_cmean_neg\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "SVD\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "NMF\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "SlopeOne\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "4\n",
      "cur_cmean_pos\n",
      "cur_cmean_neu\n",
      "cur_cmean_neg\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "SVD\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "NMF\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "SlopeOne\n",
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#all_city_pred=pd.DataFrame()\n",
    "for city in range(0,len(cities)):\n",
    "    print(city)\n",
    "    df=df_all[df_all.city==city]\n",
    "    df=df.reset_index(drop=True)\n",
    "    df=for_city(df)\n",
    "    fi,fi_index=fi_count(df,bounds)\n",
    "    cats_rest = [x for x in fi_index if x not in ['user_name', 'unique_rest', 'cur_count', \n",
    "                                              'cur_cmean_pos', 'cur_cmean_neu', 'cur_cmean_neg']]\n",
    "    cats_user = [x for x in fi_index if x in ['cur_count', 'cur_cmean_pos', 'cur_cmean_neu', 'cur_cmean_neg', 'city', 'covid']]\n",
    "    df['user_context'] = df[cats_user].values.tolist()\n",
    "    ncats_user = [df[x].nunique() for x in cats_user]\n",
    "    svd_user_pred=svd_user(df,bounds,city)\n",
    "    svd_context_pred=svd_context(df,bounds,cats_rest,city)\n",
    "    svd_cс_pred_2=cc(df,bounds,cats_rest,city)\n",
    "    all_pred=usual_methods(df,bounds,cats_rest,city)\n",
    "    all_city_pred=pd.concat([all_city_pred,svd_user_pred,svd_context_pred,svd_cс_pred_2,all_pred], ignore_index=True)\n",
    "    all_city_pred.to_csv(\"all_city_pred.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>unique_rest</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>dist</th>\n",
       "      <th>Бранч</th>\n",
       "      <th>Завтрак</th>\n",
       "      <th>Напитки</th>\n",
       "      <th>Обед</th>\n",
       "      <th>...</th>\n",
       "      <th>Электронные платежи</th>\n",
       "      <th>Азербайджанская</th>\n",
       "      <th>Словенская</th>\n",
       "      <th>Чилийская</th>\n",
       "      <th>cur_count</th>\n",
       "      <th>covid</th>\n",
       "      <th>cur_cmean_pos</th>\n",
       "      <th>cur_cmean_neu</th>\n",
       "      <th>cur_cmean_neg</th>\n",
       "      <th>user_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530sofiaaa_0B701BA503208A2FB5D3AF2844D4FB06</td>\n",
       "      <td>4</td>\n",
       "      <td>250_Stockholm</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 3, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JohanH1529_1C18195EAB577B0E5C0B075158B3DF16</td>\n",
       "      <td>3</td>\n",
       "      <td>626_Stockholm</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 2, 11, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548michaelc_AD13728165EA8E95F37CBDCF265266F5</td>\n",
       "      <td>4</td>\n",
       "      <td>290_Stockholm</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 10, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>helen692019_9F1DA5E86A2E77191F1F825015E4EB73</td>\n",
       "      <td>5</td>\n",
       "      <td>223_Stockholm</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soffitopp2_8F17C665CE80E772B0B7E11E1BC9245E</td>\n",
       "      <td>5</td>\n",
       "      <td>239_Stockholm</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[4, 0, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14789</th>\n",
       "      <td>GregorioIndelicato_1ED470D87F987CA25ED3AF34CCD...</td>\n",
       "      <td>4</td>\n",
       "      <td>404_Stockholm</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14790</th>\n",
       "      <td>120fredrikl_C2E4159838661BC41F7C465CBB655535</td>\n",
       "      <td>3</td>\n",
       "      <td>547_Stockholm</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14791</th>\n",
       "      <td>Sven_48_5D1CDAC99FBFB18D897E1A04FD114434</td>\n",
       "      <td>5</td>\n",
       "      <td>467_Stockholm</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14792</th>\n",
       "      <td>PAMM67_E2052DC25E7B434EEE83ADC728AC7E71</td>\n",
       "      <td>3</td>\n",
       "      <td>883_Stockholm</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 0, 0, 0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14793</th>\n",
       "      <td>patrikdiazsima_9A40212ECEAC3A0DAC09CE047E789EEB</td>\n",
       "      <td>5</td>\n",
       "      <td>58_Stockholm</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14794 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               user_name  rating  \\\n",
       "0            530sofiaaa_0B701BA503208A2FB5D3AF2844D4FB06       4   \n",
       "1            JohanH1529_1C18195EAB577B0E5C0B075158B3DF16       3   \n",
       "2           548michaelc_AD13728165EA8E95F37CBDCF265266F5       4   \n",
       "3           helen692019_9F1DA5E86A2E77191F1F825015E4EB73       5   \n",
       "4            Soffitopp2_8F17C665CE80E772B0B7E11E1BC9245E       5   \n",
       "...                                                  ...     ...   \n",
       "14789  GregorioIndelicato_1ED470D87F987CA25ED3AF34CCD...       4   \n",
       "14790       120fredrikl_C2E4159838661BC41F7C465CBB655535       3   \n",
       "14791           Sven_48_5D1CDAC99FBFB18D897E1A04FD114434       5   \n",
       "14792            PAMM67_E2052DC25E7B434EEE83ADC728AC7E71       3   \n",
       "14793    patrikdiazsima_9A40212ECEAC3A0DAC09CE047E789EEB       5   \n",
       "\n",
       "         unique_rest       date  city  dist  Бранч  Завтрак  Напитки  Обед  \\\n",
       "0      250_Stockholm 2021-03-09     2     2      0        0        0     1   \n",
       "1      626_Stockholm 2021-03-09     2     0      0        0        0     1   \n",
       "2      290_Stockholm 2021-03-08     2     1      0        0        0     0   \n",
       "3      223_Stockholm 2021-03-08     2     3      0        0        0     0   \n",
       "4      239_Stockholm 2021-03-07     2     1      0        0        0     1   \n",
       "...              ...        ...   ...   ...    ...      ...      ...   ...   \n",
       "14789  404_Stockholm 2019-01-02     2     2      1        0        1     1   \n",
       "14790  547_Stockholm 2019-01-02     2     1      0        0        1     1   \n",
       "14791  467_Stockholm 2019-01-02     2     1      0        0        1     1   \n",
       "14792  883_Stockholm 2019-01-02     2     3      1        0        0     1   \n",
       "14793   58_Stockholm 2019-01-02     2     2      0        0        0     1   \n",
       "\n",
       "       ...  Электронные платежи  Азербайджанская  Словенская  Чилийская  \\\n",
       "0      ...                    0                0           0          0   \n",
       "1      ...                    0                0           0          0   \n",
       "2      ...                    0                0           0          0   \n",
       "3      ...                    0                0           0          0   \n",
       "4      ...                    0                0           0          0   \n",
       "...    ...                  ...              ...         ...        ...   \n",
       "14789  ...                    0                0           0          0   \n",
       "14790  ...                    0                0           0          0   \n",
       "14791  ...                    0                0           0          0   \n",
       "14792  ...                    0                0           0          0   \n",
       "14793  ...                    0                0           0          0   \n",
       "\n",
       "       cur_count  covid  cur_cmean_pos  cur_cmean_neu  cur_cmean_neg  \\\n",
       "0              3      2              2              2              2   \n",
       "1             11      2              3              1              2   \n",
       "2             10      2              2              1              2   \n",
       "3              2      2              4              2              2   \n",
       "4              1      2              4              3              0   \n",
       "...          ...    ...            ...            ...            ...   \n",
       "14789          0      0              0              0              0   \n",
       "14790          0      0              0              0              0   \n",
       "14791          0      0              0              0              0   \n",
       "14792          0      0              3              3              0   \n",
       "14793          0      0              0              0              0   \n",
       "\n",
       "           user_context  \n",
       "0       [2, 2, 3, 2, 2]  \n",
       "1      [3, 2, 11, 2, 1]  \n",
       "2      [2, 2, 10, 2, 1]  \n",
       "3       [4, 2, 2, 2, 2]  \n",
       "4       [4, 0, 1, 2, 3]  \n",
       "...                 ...  \n",
       "14789   [0, 0, 0, 0, 0]  \n",
       "14790   [0, 0, 0, 0, 0]  \n",
       "14791   [0, 0, 0, 0, 0]  \n",
       "14792   [3, 0, 0, 0, 3]  \n",
       "14793   [0, 0, 0, 0, 0]  \n",
       "\n",
       "[14794 rows x 198 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавление новых столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# расстояние до центра в перцентилях\n",
    "def dist2category(city, dist, city_dist_dict):\n",
    "    temp = []\n",
    "    for c,d in zip(city, dist):\n",
    "        if d<=city_dist_dict[c]['25%']:\n",
    "            temp.append(0)\n",
    "        elif city_dist_dict[c]['25%']<d<=city_dist_dict[c]['50%']:\n",
    "            temp.append(1)\n",
    "        elif city_dist_dict[c]['50%']<d<=city_dist_dict[c]['75%']:\n",
    "            temp.append(2)\n",
    "        else:\n",
    "            temp.append(3)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_count2cur_count_category(x):\n",
    "    if x==0:\n",
    "        return 0\n",
    "    if x==1:\n",
    "        return 1\n",
    "    if x==2:\n",
    "        return 2\n",
    "    if x==3:\n",
    "        return 3\n",
    "    if x==4:\n",
    "        return 4\n",
    "    if x==5:\n",
    "        return 5\n",
    "    if x==6:\n",
    "        return 6\n",
    "    if x==7:\n",
    "        return 7\n",
    "    if x==8:\n",
    "        return 8\n",
    "    if x==9:\n",
    "        return 9\n",
    "    if 10<=x<20:\n",
    "        return 10\n",
    "    if x>=20:\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_sent2cur_sent_category(x, col, tdict):\n",
    "    if x==0:\n",
    "        return 0\n",
    "    elif 0 < x <= tdict[col]['25%']:\n",
    "        return 1\n",
    "    elif tdict[col]['25%'] < x <= tdict[col]['50%']:\n",
    "        return 2\n",
    "    elif tdict[col]['50%'] < x <= tdict[col]['75%']:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#даты в зависимости от ковид\n",
    "bounds = {'before_covid':[datetime.datetime(2020,1,1), datetime.datetime(2020,3,20)],\n",
    "          'during_covid':[datetime.datetime(2020,3,20), datetime.datetime(2020,8,1)], \n",
    "          'after_covid':[datetime.datetime(2020,8,2), datetime.datetime(2020,10,1)]}\n",
    "def func(date):\n",
    "    if date<=bounds['before_covid'][1]:\n",
    "        return 0\n",
    "    if bounds['during_covid'][0]<=date<=bounds['during_covid'][1]:\n",
    "        return 1\n",
    "    if bounds['after_covid'][0]<=date:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модели и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def mapak(predicted, true, k):\n",
    "    apaks = []\n",
    "    predicted_ = copy.deepcopy(predicted)\n",
    "    for u in predicted_.keys():\n",
    "        if u not in true or len(predicted_[u]) == 0:\n",
    "            apaks.append(0.0)\n",
    "            continue\n",
    "        if len(predicted_[u]) > k:\n",
    "            predicted_[u] = predicted_[u][:k]\n",
    "        count = 0.0\n",
    "        score = 0.0\n",
    "        for i, p in enumerate(predicted_[u]):\n",
    "            if p in true[u] and p not in predicted_[u][:i]:\n",
    "                count += 1.0\n",
    "                score += count/(i+1.0)\n",
    "        temp = score/min(len(predicted_[u]), k)\n",
    "        apaks.append(temp)\n",
    "    return np.mean(apaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratata(x):\n",
    "    if 1<=x<1.5:\n",
    "        return 0\n",
    "    if 1.5<=x<2:\n",
    "        return 1\n",
    "    if 2<=x<2.5:\n",
    "        return 2\n",
    "    if 2.5<=x<3:\n",
    "        return 3\n",
    "    if 3<=x<3.5:\n",
    "        return 4\n",
    "    if 3.5<=x<4:\n",
    "        return 5\n",
    "    if 4<=x<4.5:\n",
    "        return 6\n",
    "    if 4.5<=x<=5:\n",
    "        return 7\n",
    "    \n",
    "def func_desc(x, desc):\n",
    "    if x==0:\n",
    "        return 0\n",
    "    elif 0 < x <= desc['25%']:\n",
    "        return 1\n",
    "    elif desc['25%'] < x <= desc['50%']:\n",
    "        return 2\n",
    "    elif desc['50%'] < x <= desc['75%']:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С КОНТЕКСТОМ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD_CONTEXT_USER():\n",
    "    def __init__(self, mat, context_mat, k, iterations, gamma_1, gamma_2, gamma_3, lambda_6, lambda_7, lambda_8, cats, ncats):\n",
    "        self.R = mat.to_numpy()\n",
    "        self.R_ = mat.T.to_numpy()\n",
    "        self.context_mat = context_mat\n",
    "        self.num_users, self.num_items = self.R.shape\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "\n",
    "        self.users = mat.index.tolist()\n",
    "        self.items = mat.columns.tolist()\n",
    "\n",
    "        self.gamma_1 = gamma_1\n",
    "        self.gamma_2 = gamma_2\n",
    "        self.gamma_3 = gamma_3\n",
    "        self.lambda_6 = lambda_6\n",
    "        self.lambda_7 = lambda_7\n",
    "        self.lambda_8 = lambda_8\n",
    "\n",
    "        self.P = np.random.normal(scale=1. / self.k, size=(self.num_users, self.k))\n",
    "        self.Q = np.random.normal(scale=1. / self.k, size=(self.num_items, self.k))\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        self.samples = self.get_samples()\n",
    "        self.cats = cats\n",
    "        self.contextNum = ncats\n",
    "        self.btcj = self.get_btcj()\n",
    "\n",
    "    def get_btcj(self):\n",
    "        btcj = list()\n",
    "        for i in range(self.num_users):\n",
    "            contextDict = dict()\n",
    "            for j in range(len(self.contextNum)):\n",
    "                contextDict[j] = [0.0 for z in range(self.contextNum[j])]\n",
    "            btcj.append(contextDict)\n",
    "        return btcj\n",
    "\n",
    "    def get_samples(self):\n",
    "        samples = [\n",
    "            (i, j, self.R[i, j], self.context_mat[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        return samples\n",
    "\n",
    "    def train(self):\n",
    "        print('train start')\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            ctx = self.context_mat[x, y]\n",
    "            error += pow(self.R[x, y] - self.get_rating(x, y, ctx), 2)\n",
    "        return np.sqrt(error / len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r, context in self.samples:\n",
    "            prediction = self.get_rating(i, j, context)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.gamma_1 * (e - self.lambda_6 * self.b_u[i])\n",
    "            self.b_i[j] += self.gamma_1 * (e - self.lambda_6 * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :][:]\n",
    "            self.P[i, :] += self.gamma_2 * (e * self.Q[j, :] - self.lambda_7 * self.P[i, :])\n",
    "            self.Q[j, :] += self.gamma_2 * (e * P_i - self.lambda_7 * self.Q[j, :])\n",
    "\n",
    "            for key, values in self.btcj[i].items():\n",
    "                value = values[context[key]]\n",
    "                value += self.gamma_3 * (e - self.lambda_8 * value)\n",
    "                self.btcj[i][key][context[key]] = value\n",
    "\n",
    "\n",
    "    def get_rating(self, i, j, context):\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "#         prediction = self.b + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)        \n",
    "        for key, value in self.btcj[i].items():\n",
    "            if context[key] >= 0:\n",
    "                prediction += value[int(context[key])]\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, user, item, context):\n",
    "        prediction = self.b\n",
    "        if user in self.users:\n",
    "            i = self.users.index(user)\n",
    "            prediction+=self.b_u[i]\n",
    "            for key, value in self.btcj[i].items():\n",
    "                if context[key] >= 0:\n",
    "                    prediction += value[int(context[key])]\n",
    "        if item in self.items:\n",
    "            j = self.items.index(item)\n",
    "            prediction+=self.b_i[j]\n",
    "        if user in self.users and item in self.items:\n",
    "            prediction+=self.P[i, :].dot(self.Q[j, :].T)\n",
    "        if prediction > 5:\n",
    "            return 5\n",
    "        elif prediction < 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return prediction\n",
    "    \n",
    "    def predict_all(self, user, nrests, contexts):\n",
    "        i = self.users.index(user)\n",
    "        pred1 = np.full(nrests, self.b)\n",
    "        pred2 = np.full(nrests, self.b_u[i])\n",
    "        pred3 = self.P[i, :].dot(self.Q.T)\n",
    "        pred4 = self.b_i\n",
    "        pred5 = []\n",
    "        for ii, x in enumerate(contexts):\n",
    "            if ii > nrests-1:\n",
    "                break\n",
    "            pred5.append((sum([v[int(x[k])] for k,v in self.btcj[i].items()])))\n",
    "        return pred1+pred2+pred3+pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD_CONTEXT_ITEM():\n",
    "    def __init__(self, mat, context_mat, k, iterations, \n",
    "                 gamma_1, gamma_2, gamma_3,\n",
    "                 lambda_6, lambda_7, lambda_8,\n",
    "                 cats, ncats):\n",
    "        self.R = mat.to_numpy()\n",
    "        self.R_ = mat.T.to_numpy()\n",
    "        self.context_mat = context_mat\n",
    "        self.num_users, self.num_items = self.R.shape\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "\n",
    "        self.users = mat.index.tolist()\n",
    "        self.items = mat.columns.tolist()\n",
    "\n",
    "        self.gamma_1 = gamma_1\n",
    "        self.gamma_2 = gamma_2\n",
    "        self.gamma_3 = gamma_3\n",
    "        self.lambda_6 = lambda_6\n",
    "        self.lambda_7 = lambda_7\n",
    "        self.lambda_8 = lambda_8\n",
    "\n",
    "        self.P = np.random.normal(scale=1. / self.k, size=(self.num_users, self.k))\n",
    "        self.Q = np.random.normal(scale=1. / self.k, size=(self.num_items, self.k))\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        self.samples = self.get_samples()\n",
    "        self.cats = cats\n",
    "        self.ncats = ncats\n",
    "        self.contextNum = ncats\n",
    "        self.btcj = self.get_btcj()\n",
    "\n",
    "    def get_btcj(self):\n",
    "        btcj = list()\n",
    "        for i in range(self.num_items):\n",
    "            contextDict = dict()\n",
    "            for j in range(len(self.contextNum)):\n",
    "                contextDict[j] = [0.0 for z in range(self.contextNum[j])]\n",
    "            btcj.append(contextDict)\n",
    "        return btcj\n",
    "\n",
    "    def get_samples(self):\n",
    "        samples = [\n",
    "            (i, j, self.R[i, j], self.context_mat[j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        return samples\n",
    "\n",
    "    def train(self):\n",
    "        print('train start')\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            ctx = self.context_mat[y]\n",
    "            error += pow(self.R[x, y] - self.get_rating(x, y, ctx), 2)\n",
    "        return np.sqrt(error / len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r, context in self.samples:\n",
    "            prediction = self.get_rating(i, j, context)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.gamma_1 * (e - self.lambda_6 * self.b_u[i])\n",
    "            self.b_i[j] += self.gamma_1 * (e - self.lambda_6 * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :][:]\n",
    "            self.P[i, :] += self.gamma_2 * (e * self.Q[j, :] - self.lambda_7 * self.P[i, :])\n",
    "            self.Q[j, :] += self.gamma_2 * (e * P_i - self.lambda_7 * self.Q[j, :])\n",
    "\n",
    "            for key, values in self.btcj[j].items():\n",
    "                value = values[context[key]]\n",
    "                value += self.gamma_3 * (e - self.lambda_8 * value)\n",
    "                self.btcj[j][key][context[key]] = value\n",
    "\n",
    "\n",
    "    def get_rating(self, i, j, context):\n",
    "#         prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        prediction = self.b + self.b_u[i] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        for key, value in self.btcj[j].items():\n",
    "            if context[key] >= 0:\n",
    "                prediction += value[int(context[key])]\n",
    "            else:\n",
    "                prediction += self.b_i[j]\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, user, item, context):\n",
    "        prediction = self.b\n",
    "        if user in self.users:\n",
    "            i = self.users.index(user)\n",
    "            prediction+=self.b_u[i]\n",
    "        if item in self.items:\n",
    "            j = self.items.index(item)\n",
    "            for key, value in self.btcj[j].items():\n",
    "                if context[key] >= 0:\n",
    "                    prediction += value[int(context[key])]\n",
    "                else:\n",
    "                    prediction+=self.b_i[j]\n",
    "        if user in self.users and item in self.items:\n",
    "            prediction+=self.P[i, :].dot(self.Q[j, :].T)\n",
    "        if prediction > 5:\n",
    "            return 5\n",
    "        elif prediction < 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return prediction\n",
    "        \n",
    "        \n",
    "    def predict_all(self, user, nrests):\n",
    "        i = self.users.index(user)\n",
    "        pred1 = np.full(nrests, self.b)\n",
    "        pred2 = np.full(nrests, self.b_u[i])\n",
    "        pred3 = self.P[i, :].dot(self.Q.T)\n",
    "        pred4 = self.b_i\n",
    "        pred5 = []\n",
    "        for ii, x in enumerate(self.context_mat):\n",
    "            if ii > nrests-1:\n",
    "                break\n",
    "            pred5.append((sum([v[int(x[k])] for k,v in self.btcj[ii].items()])))\n",
    "        return pred1+pred2+pred3+pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAMF_CC():\n",
    "    def __init__(self, mat, context_mat, k, iterations, \n",
    "                 gamma_1, gamma_2, gamma_3, \n",
    "                 lambda_6, lambda_7, lambda_8, \n",
    "                 cats, ncats, categoryNum, gr_index):\n",
    "        self.R = mat.to_numpy()\n",
    "        self.R_ = mat.T.to_numpy()\n",
    "        self.context_mat = context_mat\n",
    "        self.num_users, self.num_items = self.R.shape\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "\n",
    "        self.users = mat.index.tolist()\n",
    "        self.items = mat.columns.tolist()\n",
    "\n",
    "        self.gamma_1 = gamma_1\n",
    "        self.gamma_2 = gamma_2\n",
    "        self.gamma_3 = gamma_3\n",
    "        self.lambda_6 = lambda_6\n",
    "        self.lambda_7 = lambda_7\n",
    "        self.lambda_8 = lambda_8\n",
    "\n",
    "        self.P = np.random.normal(scale=1. / self.k, size=(self.num_users, self.k))\n",
    "        self.Q = np.random.normal(scale=1. / self.k, size=(self.num_items, self.k))\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        self.samples = self.get_samples()\n",
    "        self.cats = cats\n",
    "        self.ncats = ncats\n",
    "        self.contextNum = ncats\n",
    "        self.categoryNum = categoryNum\n",
    "        self.btcj = self.get_btcj()\n",
    "        self.gr_index = gr_index\n",
    "\n",
    "    def get_btcj(self):\n",
    "        btcj = list()\n",
    "        for i in range(self.categoryNum):\n",
    "            contextDict = dict()\n",
    "            for j in range(len(self.contextNum)):\n",
    "                contextDict[j] = [0.0 for z in range(self.contextNum[j])]\n",
    "            btcj.append(contextDict)\n",
    "        return btcj\n",
    "\n",
    "    def get_samples(self):\n",
    "        samples = [\n",
    "            (i, j, self.R[i, j], self.context_mat[j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        return samples\n",
    "\n",
    "    def train(self):\n",
    "        print('train start')\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            ctx = self.context_mat[y]\n",
    "            error += pow(self.R[x, y] - self.get_rating(x, y, ctx), 2)\n",
    "        return np.sqrt(error / len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r, context in self.samples:\n",
    "            prediction = self.get_rating(i, j, context)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.gamma_1 * (e - self.lambda_6 * self.b_u[i])\n",
    "            self.b_i[j] += self.gamma_1 * (e - self.lambda_6 * self.b_i[j])\n",
    "\n",
    "            P_i = self.P[i, :][:]\n",
    "            self.P[i, :] += self.gamma_2 * (e * self.Q[j, :] - self.lambda_7 * self.P[i, :])\n",
    "            self.Q[j, :] += self.gamma_2 * (e * P_i - self.lambda_7 * self.Q[j, :])\n",
    "            \n",
    "            cid = self.context_mat[j, self.gr_index]\n",
    "            for key, values in self.btcj[cid].items():\n",
    "                value = values[context[key]]\n",
    "                value += self.gamma_3 * (e - self.lambda_8 * value)\n",
    "                self.btcj[cid][key][context[key]] = value\n",
    "\n",
    "\n",
    "    def get_rating(self, i, j, context):\n",
    "        prediction = self.b + self.b_u[i] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        cid = context[self.gr_index]\n",
    "        for key, value in self.btcj[cid].items():\n",
    "            if context[key] >= 0:\n",
    "                prediction += value[int(context[key])]\n",
    "            else:\n",
    "                prediction += self.b_i[j]\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, user, item, context):\n",
    "        prediction = self.b\n",
    "        cid = context[self.gr_index]\n",
    "        for key, value in self.btcj[cid].items():\n",
    "            if context[key] >= 0:\n",
    "                prediction += value[int(context[key])]\n",
    "        if item in self.items:\n",
    "            j = self.items.index(item)\n",
    "#             prediction+=self.b_i[j]\n",
    "        if user in self.users:\n",
    "            i = self.users.index(user)\n",
    "            prediction+=self.b_u[i]\n",
    "        if user in self.users and item in self.items:\n",
    "            prediction+=self.P[i, :].dot(self.Q[j, :].T)\n",
    "        if prediction > 5:\n",
    "            return 5\n",
    "        elif prediction < 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return prediction\n",
    "    \n",
    "    \n",
    "    def predict_all(self, user, nrests):\n",
    "        i = self.users.index(user)\n",
    "        pred1 = np.full(nrests, self.b)\n",
    "        pred2 = np.full(nrests, self.b_u[i])\n",
    "        pred3 = self.P[i, :].dot(self.Q.T)\n",
    "        pred4 = self.b_i\n",
    "        pred5 = []\n",
    "        for ii, x in enumerate(self.context_mat):\n",
    "            cid = x[self.gr_index]\n",
    "            if ii > nrests-1:\n",
    "                break\n",
    "            pred5.append((sum([v[int(x[k])] for k,v in self.btcj[cid].items()])))\n",
    "        return pred1+pred2+pred3+pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df,date_start,date_end):\n",
    "    df_train = df[(df.date.between(date_start-dateutil.relativedelta.relativedelta(months=6), \n",
    "                                   date_start-dateutil.relativedelta.relativedelta(days=1)))]\n",
    "    df_test = df[(df.date.between(date_start, date_end))]\n",
    "    #пользователи и рестораны только те которые в трейне\n",
    "    df_test = df_test[(df_test.user_name.isin(df_train.user_name.unique().tolist()))\n",
    "                       &(df_test.unique_rest.isin(df_train.unique_rest.unique().tolist()))]\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_user(df,bounds,city):\n",
    "    ndcg = NDCG(10)\n",
    "    svd_user_pred = pd.DataFrame()\n",
    "    for i,k in enumerate(bounds.keys()):\n",
    "        print(bounds[k][0], bounds[k][1])\n",
    "        met = pd.DataFrame()\n",
    "        df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "        mat_train = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        mat_train = mat_train.sort_values('user_name')\n",
    "        mat_train = mat_train.reindex(sorted(mat_train.columns), axis=1)\n",
    "        user_context_mat = df_train.pivot(index='user_name', columns='unique_rest', values='user_context').fillna(0)\n",
    "        user_context_mat = user_context_mat.sort_values('user_name')\n",
    "        user_context_mat = user_context_mat.reindex(sorted(mat_train.columns), axis=1)\n",
    "        user_context_mat.fillna(0, inplace=True)\n",
    "        user_context_mat_ = user_context_mat.to_numpy()\n",
    "        user_context_mat_test = df_test.pivot(index='user_name', columns='unique_rest', values='user_context').fillna(0)\n",
    "        user_context_mat_test = user_context_mat_test.sort_values('user_name')\n",
    "        user_context_mat_test.fillna(0, inplace=True)\n",
    "        user_context_mat_test_ = user_context_mat_test.to_numpy()\n",
    "        mdl = SVD_CONTEXT_USER(mat = mat_train,context_mat = user_context_mat_,k = 100,iterations = 20,\n",
    "                      gamma_1 = 0.005,gamma_2 = 0.005, gamma_3 = 0.005, lambda_6 = 0.02, lambda_7 = 0.02,\n",
    "                      lambda_8 = 0.02,cats=cats_user, ncats=ncats_user)\n",
    "        mdl.train()\n",
    "        print('train_end')\n",
    "        rate_ = []\n",
    "        for x, y in zip(df_test['user_name'].tolist(), df_test['unique_rest'].tolist()):\n",
    "             rate_.append(mdl.predict(x, y, user_context_mat_test_[user_context_mat_test.index.tolist().index(x),\n",
    "                                                              user_context_mat_test.columns.tolist().index(y)]))\n",
    "        rmse = mean_squared_error(y_pred=rate_, y_true=df_test.rating, squared=False)\n",
    "        mae = mean_absolute_error(y_pred=rate_, y_true=df_test.rating)\n",
    "        print('ranking metrics')\n",
    "        \n",
    "        df_test_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_test_ = df_test_[df_test_.index.isin(df_test.user_name.unique().tolist())]\n",
    "        df_test_.update(df_test.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0))\n",
    "    \n",
    "        df_train_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_train_ = df_train_[df_train_.index.isin(df_train.user_name.unique().tolist())]\n",
    "        df_test_dict = df_test_.T.to_dict('list')\n",
    "    \n",
    "        user_context_mat.update(user_context_mat_test)\n",
    "        us = {}\n",
    "        for u in df_test_.index.tolist():\n",
    "            temp = df_test.sort_values('date').groupby('user_name')['user_context'].agg('first')\n",
    "            user_contexts = [x if x!=0 else temp[u] for x in user_context_mat.loc[u].tolist()]\n",
    "            values = mdl.predict_all(u, len(df_train_.columns), user_contexts)\n",
    "            iis = [i for i,x in enumerate(df_train_.loc[u].to_list()) if x!=0]\n",
    "            np.put(values, iis, [0 for x in iis])\n",
    "            us[u] = values\n",
    "        ndcg_metric = {}\n",
    "        for kk in us.keys():\n",
    "            ndcg_metric[kk] = ndcg.compute(df_test_dict[kk], np.array(us[kk]).argsort()[::-1])\n",
    "        ndcg_ = np.mean(list(ndcg_metric.values()))\n",
    "        mapak10 = mapak(us, df_test_dict, 10)\n",
    "        met = met.append({\n",
    "            'alg':'SVD_USER',\n",
    "            'period': (str(bounds[k][0])[:7]+' - '+str(bounds[k][1])[:7]),\n",
    "            \"city\":city,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'ndcg10': ndcg_,\n",
    "            'mapak10': mapak10\n",
    "        }, ignore_index=True)\n",
    "        svd_user_pred = svd_user_pred.append(met, ignore_index=True)\n",
    "    return svd_user_pred     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_context(df,bounds,сast_rest,city):\n",
    "    ndcg = NDCG(10)\n",
    "    svd_context_pred = pd.DataFrame()\n",
    "    for i,k in enumerate(bounds.keys()):\n",
    "        print(bounds[k][0], bounds[k][1])\n",
    "        met = pd.DataFrame()\n",
    "        df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "        #средний рейтинг\n",
    "        temp = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].mean().reset_index().rename(columns={'rating':'average_rating'})\n",
    "        temp['average_rating'] = temp.average_rating.apply(lambda x: ratata(x))\n",
    "        temp_avg_rating2cat_dict = {x:i for i,x in enumerate(temp['average_rating'].unique().tolist())}\n",
    "        temp['average_rating'] = temp['average_rating'].apply(lambda x: temp_avg_rating2cat_dict[x])\n",
    "        #количество оценок\n",
    "        temp1 = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].count().reset_index().rename(columns={'rating':'num_all_rev'})\n",
    "        temp1['num_all_rev'] = temp1.num_all_rev.apply(lambda x: func_desc(x, temp1['num_all_rev'].describe()))\n",
    "        temp1_avg_rating2cat_dict = {x:i for i,x in enumerate(temp1['num_all_rev'].unique().tolist())}\n",
    "        temp1['num_all_rev'] = temp1['num_all_rev'].apply(lambda x: temp1_avg_rating2cat_dict[x])\n",
    "        \n",
    "        df_train = df_train.merge(temp, on='unique_rest')\n",
    "        df_test = df_test.merge(temp, on='unique_rest')\n",
    "        df_train = df_train.merge(temp1, on='unique_rest')\n",
    "        df_test = df_test.merge(temp1, on='unique_rest')\n",
    "        mat_train = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        mat_train = mat_train.sort_values('user_name')\n",
    "        mat_train = mat_train.reindex(sorted(mat_train.columns), axis=1)\n",
    "        rests = df_train.drop_duplicates('unique_rest').reset_index()\n",
    "#     rests = df.drop_duplicates('unique_rest').reset_index().merge(temp, on='unique_rest')\n",
    "        rests = rests[['unique_rest'] + cats_rest]\n",
    "        ncats = [rests[x].nunique() for x in cats_rest]\n",
    "        name_index_rest = {i:x for i,x in enumerate(rests.unique_rest.unique())}\n",
    "        nrests = len(name_index_rest)\n",
    "        mat_mat = rests.set_index('unique_rest')[cats_rest].sort_index()\n",
    "        mat_mat.fillna(0, inplace=True)\n",
    "        mat_mat_ = mat_mat.to_numpy()\n",
    "        mdl = SVD_CONTEXT_ITEM(mat = mat_train,context_mat = mat_mat_,k = 100,iterations = 20,gamma_1 = 0.005,\n",
    "                  gamma_2 = 0.005,gamma_3 = 0.005,lambda_6 = 0.02,lambda_7 = 0.02,lambda_8 = 0.02,cats=cats_rest,ncats=ncats)\n",
    "        mdl.train()\n",
    "        print('train_end')\n",
    "        pred = []\n",
    "        for x, y in zip(df_test['user_name'].tolist(), df_test['unique_rest'].tolist()):\n",
    "            pred.append(mdl.predict(x, y, mat_mat_[mat_mat.index.tolist().index(y)]))\n",
    "        rmse = mean_squared_error(y_pred=pred, y_true=df_test.rating, squared=False)\n",
    "        mae = mean_absolute_error(y_pred=pred, y_true=df_test.rating)\n",
    "        df_test_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_test_ = df_test_[df_test_.index.isin(df_test.user_name.unique().tolist())]\n",
    "        df_test_.update(df_test.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0))\n",
    "        df_train_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_train_ = df_train_[df_train_.index.isin(df_train.user_name.unique().tolist())]\n",
    "        df_test_dict = df_test_.T.to_dict('list')\n",
    "        print('ranking metrics')\n",
    "        us = {}\n",
    "        for u in df_test_.index.tolist():\n",
    "            values = mdl.predict_all(u, len(df_train_.columns))\n",
    "            iis = [i for i,x in enumerate(df_train_.loc[u].to_list()) if x!=0]\n",
    "            np.put(values, iis, [0 for x in iis])\n",
    "            us[u] = values\n",
    "        ndcg_metric = {}\n",
    "        for kk in us.keys():\n",
    "            ndcg_metric[kk] = ndcg.compute(df_test_dict[kk], np.array(us[kk]).argsort()[::-1])\n",
    "        ndcg_ = np.mean(list(ndcg_metric.values()))\n",
    "        mapak10 = mapak(us, df_test_dict, 10)   \n",
    "        met = met.append({\n",
    "            'alg':'SVD_CONTEXT',\n",
    "            'period': (str(bounds[k][0])[:7]+' - '+str(bounds[k][1])[:7]),\n",
    "            \"city\":city,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'ndcg10': ndcg_,\n",
    "            'mapak10': mapak10\n",
    "             }, ignore_index=True)\n",
    "        svd_context_pred = svd_context_pred.append(met, ignore_index=True)\n",
    "    return svd_context_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_index = cats_rest.index('average_rating')\n",
    "met = pd.DataFrame()\n",
    "df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "temp = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].mean().reset_index().rename(columns={'rating':'average_rating'})\n",
    "temp['average_rating'] = temp.average_rating.apply(lambda x: ratata(x))\n",
    "temp_avg_rating2cat_dict = {x:i for i,x in enumerate(temp['average_rating'].unique().tolist())}\n",
    "temp['average_rating'] = temp['average_rating'].apply(lambda x: temp_avg_rating2cat_dict[x])\n",
    "temp1 = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].count().reset_index().rename(columns={'rating':'num_all_rev'})\n",
    "temp1['num_all_rev'] = temp1.num_all_rev.apply(lambda x: func_desc(x, temp1['num_all_rev'].describe()))\n",
    "temp1_avg_rating2cat_dict = {x:i for i,x in enumerate(temp1['num_all_rev'].unique().tolist())}\n",
    "temp1['num_all_rev'] = temp1['num_all_rev'].apply(lambda x: temp1_avg_rating2cat_dict[x])\n",
    "df_train = df_train.merge(temp, on='unique_rest')\n",
    "df_test = df_test.merge(temp, on='unique_rest')\n",
    "df_train = df_train.merge(temp1, on='unique_rest')\n",
    "df_test = df_test.merge(temp1, on='unique_rest')\n",
    "mat_train = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "mat_train = mat_train.sort_values('user_name')\n",
    "mat_train = mat_train.reindex(sorted(mat_train.columns), axis=1)\n",
    "rests = df_train.drop_duplicates('unique_rest').reset_index()\n",
    "rests = rests[['unique_rest'] + cats_rest]\n",
    "ncats = [rests[x].nunique() for x in cats_rest]\n",
    "name_index_rest = {i:x for i,x in enumerate(rests.unique_rest.unique())}\n",
    "nrests = len(name_index_rest)\n",
    "mat_mat = rests.set_index('unique_rest')[cats_rest].sort_index()\n",
    "mat_mat.fillna(0, inplace=True)\n",
    "mat_mat_ = mat_mat.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       3\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "1786    3\n",
       "1787    2\n",
       "1788    2\n",
       "1789    0\n",
       "1790    3\n",
       "Name: average_rating, Length: 1791, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[cats_rest[group_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc(df,bounds,сast_rest,city):\n",
    "    svd_cс_pred_2 = pd.DataFrame()\n",
    "    ndcg = NDCG(10)\n",
    "    group_index = cats_rest.index('average_rating')\n",
    "    for i,k in enumerate(bounds.keys()):\n",
    "        print(bounds[k][0], bounds[k][1])\n",
    "        met = pd.DataFrame()\n",
    "        df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "        temp = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].mean().reset_index().rename(columns={'rating':'average_rating'})\n",
    "        temp['average_rating'] = temp.average_rating.apply(lambda x: ratata(x))\n",
    "        temp_avg_rating2cat_dict = {x:i for i,x in enumerate(temp['average_rating'].unique().tolist())}\n",
    "        temp['average_rating'] = temp['average_rating'].apply(lambda x: temp_avg_rating2cat_dict[x])\n",
    "        temp1 = df[df.date<bounds[k][0]].groupby('unique_rest')['rating'].count().reset_index().rename(columns={'rating':'num_all_rev'})\n",
    "        temp1['num_all_rev'] = temp1.num_all_rev.apply(lambda x: func_desc(x, temp1['num_all_rev'].describe()))\n",
    "        temp1_avg_rating2cat_dict = {x:i for i,x in enumerate(temp1['num_all_rev'].unique().tolist())}\n",
    "        temp1['num_all_rev'] = temp1['num_all_rev'].apply(lambda x: temp1_avg_rating2cat_dict[x])\n",
    "    \n",
    "        df_train = df_train.merge(temp, on='unique_rest')\n",
    "        df_test = df_test.merge(temp, on='unique_rest')\n",
    "        df_train = df_train.merge(temp1, on='unique_rest')\n",
    "        df_test = df_test.merge(temp1, on='unique_rest')\n",
    "        mat_train = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        mat_train = mat_train.sort_values('user_name')\n",
    "        mat_train = mat_train.reindex(sorted(mat_train.columns), axis=1)\n",
    "\n",
    "        rests = df_train.drop_duplicates('unique_rest').reset_index()\n",
    "        rests = rests[['unique_rest'] + cats_rest]\n",
    "        ncats = [rests[x].nunique() for x in cats_rest]\n",
    "        name_index_rest = {i:x for i,x in enumerate(rests.unique_rest.unique())}\n",
    "        nrests = len(name_index_rest)\n",
    "\n",
    "        mat_mat = rests.set_index('unique_rest')[cats_rest].sort_index()\n",
    "        mat_mat.fillna(0, inplace=True)\n",
    "        mat_mat_ = mat_mat.to_numpy()\n",
    "    \n",
    "        mdl = CAMF_CC(mat = mat_train,\n",
    "                  context_mat = mat_mat_,\n",
    "                  k = 100,\n",
    "                  iterations = 20,\n",
    "                  gamma_1 = 0.005,\n",
    "                  gamma_2 = 0.005,\n",
    "                  gamma_3 = 0.005,\n",
    "                  lambda_6 = 0.02,\n",
    "                  lambda_7 = 0.02,\n",
    "                  lambda_8 = 0.02,\n",
    "                  cats=cats_rest,\n",
    "                  ncats=ncats,\n",
    "                  categoryNum=df_train[cats_rest[group_index]].nunique(),\n",
    "                  gr_index=group_index)\n",
    "        mdl.train()\n",
    "        print('train_end')\n",
    "        pred = []\n",
    "        for x, y in zip(df_test['user_name'].tolist(), df_test['unique_rest'].tolist()):\n",
    "            pred.append(mdl.predict(x, y, mat_mat_[mat_mat.index.tolist().index(y)]))\n",
    "        rmse = mean_squared_error(y_pred=pred, y_true=df_test.rating, squared=False)\n",
    "        mae = mean_absolute_error(y_pred=pred, y_true=df_test.rating)\n",
    "    \n",
    "        df_test_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_test_ = df_test_[df_test_.index.isin(df_test.user_name.unique().tolist())]\n",
    "        df_test_.update(df_test.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0))\n",
    "    \n",
    "        df_train_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "        df_train_ = df_train_[df_train_.index.isin(df_train.user_name.unique().tolist())]\n",
    "        df_test_dict = df_test_.T.to_dict('list')\n",
    "        print('ranking metrics start')\n",
    "        us = {}\n",
    "        for u in df_test_.index.tolist():\n",
    "            values = mdl.predict_all(u, len(df_train_.columns))\n",
    "            iis = [i for i,x in enumerate(df_train_.loc[u].to_list()) if x!=0]\n",
    "            np.put(values, iis, [0 for x in iis])\n",
    "            us[u] = values\n",
    "        ndcg_metric = {}\n",
    "        for kk in us.keys():\n",
    "            ndcg_metric[kk] = ndcg.compute(df_test_dict[kk], np.array(us[kk]).argsort()[::-1])\n",
    "        ndcg_ = np.mean(list(ndcg_metric.values()))\n",
    "        mapak10 = mapak(us, df_test_dict, 10)\n",
    "        print('ranking metrics end')\n",
    "        met = met.append({\n",
    "            'alg':'SVD_CONTEXT_CC_AR',\n",
    "            'period': (str(bounds[k][0])[:7]+' - '+str(bounds[k][1])[:7]),\n",
    "            \"city\":city,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'ndcg10': ndcg_,\n",
    "            'mapak10': mapak10\n",
    "            }, ignore_index=True)\n",
    "        svd_cс_pred_2 = svd_cс_pred_2.append(met, ignore_index=True)\n",
    "    return svd_cс_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics start\n",
      "ranking metrics end\n"
     ]
    }
   ],
   "source": [
    "svd_cс_pred_2=cc(df,bounds,cats_rest,city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n"
     ]
    }
   ],
   "source": [
    "svd_user_pred=svd_user(df,bounds)\n",
    "svd_context_pred=svd_context(df,bounds,cats_rest)\n",
    "svd_cс_pred_2=(df,bounds,cats_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00 2020-03-20 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-03-20 00:00:00 2020-08-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n",
      "2020-08-02 00:00:00 2020-10-01 00:00:00\n",
      "train start\n",
      "train_end\n",
      "ranking metrics\n"
     ]
    }
   ],
   "source": [
    "svd_context_pred=svd_context(df,bounds,cats_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стандартные методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usual_methods(df,bounds,сast_rest,city):\n",
    "    results_surprise = pd.DataFrame()\n",
    "    algos = {\n",
    "        'SVD': SVD(),\n",
    "        'NMF': NMF(),\n",
    "        'SlopeOne' : SlopeOne(),\n",
    "    }\n",
    "    ndcg = NDCG(10)\n",
    "    all_pred = pd.DataFrame()\n",
    "    for alg in algos:\n",
    "        print(alg)\n",
    "        for i,k in enumerate(bounds.keys()):\n",
    "            print(bounds[k][0], bounds[k][1])\n",
    "            met = pd.DataFrame()\n",
    "            df_train,df_test=create_train_test(df,bounds[k][0], bounds[k][1])\n",
    "            df_train=df_train[['user_name', 'unique_rest', 'rating']]\n",
    "            df_test=df_test[['user_name', 'unique_rest', 'rating']]\n",
    "            reader = Reader(rating_scale=(1, 5))\n",
    "            data_do_train = Dataset.load_from_df(df_train, reader)\n",
    "            trainset = data_do_train.build_full_trainset()\n",
    "            algo = algos[alg]\n",
    "            algo.fit(trainset)  \n",
    "            df_test_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "            df_test_ = df_test_[df_test_.index.isin(df_test.user_name.unique().tolist())]\n",
    "            df_test_.update(df_test.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0))\n",
    "            df_train_ = df_train.pivot(index='user_name', columns='unique_rest', values='rating').fillna(0)\n",
    "            df_train_ = df_train_[df_train_.index.isin(df_train.user_name.unique().tolist())]\n",
    "            df_test_dict = df_test_.T.to_dict('list')\n",
    "            us = {}\n",
    "            for u in df_test_.index.tolist():\n",
    "                values = [algo.predict(u, i).est if df_train_.loc[u, i]==0 else 0 for i in df_test_.columns.tolist()]\n",
    "                us[u] = values\n",
    "            ndcg_metric = {}\n",
    "            for kk in us.keys():\n",
    "                ndcg_metric[kk] = ndcg.compute(df_test_dict[kk], np.array(us[kk]).argsort()[::-1])\n",
    "            ndcg_ = np.mean(list(ndcg_metric.values()))     \n",
    "            test_ui_dict = df_test.groupby('user_name')['unique_rest'].apply(list).to_dict()\n",
    "            test_ur_dict = df_test.groupby('user_name')['rating'].apply(list).to_dict()\n",
    "            pred_ur_dict_cut = {}\n",
    "            pred_ur_dict_cut_ = {}\n",
    "            for u in test_ui_dict.keys():\n",
    "                pred_ur_dict_cut[u] = [algo.predict(uid=u, iid=i).est for i in test_ui_dict[u]]# if len(test_ui_dict[u])>1]\n",
    "            for u in test_ui_dict.keys():\n",
    "                if len(test_ui_dict[u])>1:\n",
    "                    pred_ur_dict_cut_[u] = [algo.predict(uid=u, iid=i).est for i in test_ui_dict[u]]\n",
    "            ndcg_metric_cut = {}\n",
    "            ndcg_metric_cut_ = {}\n",
    "            for u in pred_ur_dict_cut.keys():\n",
    "                ndcg_metric_cut[u] = ndcg.compute(test_ur_dict[u], np.array(pred_ur_dict_cut[u]).argsort()[::-1])\n",
    "            for u in pred_ur_dict_cut_.keys():\n",
    "                ndcg_metric_cut_[u] = ndcg.compute(test_ur_dict[u], np.array(pred_ur_dict_cut_[u]).argsort()[::-1])\n",
    "            ndcg_10_cut = np.mean(list(ndcg_metric_cut.values()))\n",
    "            ndcg_10_cut_ = np.mean(list(ndcg_metric_cut_.values()))\n",
    "            mapak10 = mapak(us, df_test_dict, 10)     \n",
    "            rate_ = []\n",
    "            for x, y in zip(df_test['user_name'].tolist(), df_test['unique_rest'].tolist()):\n",
    "                rate_.append([algo.predict(uid=x,iid=y).est])\n",
    "            rmse = mean_squared_error(y_pred=rate_, y_true=df_test.rating, squared = False)\n",
    "            mae = mean_absolute_error(y_pred=rate_, y_true=df_test.rating)\n",
    "            met = met.append({\n",
    "                'alg':alg,\n",
    "                'period': (str(bounds[k][0])[:7]+' - '+str(bounds[k][1])[:7]),\n",
    "                \"city\":city,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'ndcg10': ndcg_,\n",
    "                'ndcg10_cut': ndcg_10_cut,\n",
    "                'ndcg10_cut_': ndcg_10_cut_,\n",
    "                'mapak10': mapak10\n",
    "            }, ignore_index=True)\n",
    "            all_pred = all_pred.append(met, ignore_index=True)\n",
    "    return all_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
